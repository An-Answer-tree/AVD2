# CATS: Critical Adaptive Transformer for Self-driving Captions
### This repository is an official implementation of CATS: Critical Adaptive Transformer for Self-driving Captions.
Created by Cheng Li, Keyuan Zhou, Tong Liu, Yu Wang, Mingqiao Zhuang, Kairui Ding and Hao Zhao from Institute for AI Industry Research(AIR), Tsinghua University.
### Our Project video is available at:

# Introduction
We propose a novel framework, CATS (Critical Adaptive Transformer for Self-driving Captions), which enhances transparency and explainability in autonomous driving systems by providing detailed natural language narrations and reasoning for accident scenarios. CATS jointly tackles both the accident description and prevention tasks, offering actionable insights through a shared video representation.This repository includes (will be released soon) the full implementation of CATS, along with the training and evaluation setups, the generated accident dataset EMMAU dataset and the conda environment.

# Note
### We have uploaded the requirement environment of our CATS system.
### We have released the data preprocessing codes and the evaluation codes of the project.
### We have released the preprocessed dataset of the EMMAU dataset.
### We will release the entired code of the CATS system soon.
### We will release the dataset of the generated accident video (EMMAU dataset).
### We will upload the detailed instructions of the readme document.
